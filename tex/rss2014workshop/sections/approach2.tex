\section{Approach}
    % general probabilistic model 
        % object recognition
        % action selection

    % implementation
        % object recognition, features n stuff
        % action selection, sampling n stuff

\subsection{Probabilistic Graphical Model}

    Our model consists of an object recognition subgraph extended in time for modelling actions. 
    % Objects and poses are modelled discriminatively and each feature is modelled as continuous random variable of feature matching error. 
    This model is agnostic of the type of features used so long a matching error function is defined for comparing features of the same type. Actions are optimally selected based the minimum expected entropy of the object predictions for each potential action.

    % more scientific this time?

    % OLD
        % This model has two parts. The first part deals only with object recognition and the second part extends this model for determining optimal actions. The object recognition model is a simple discriminative model for predicting object and pose. This model is agnostic of the type of features used so long as there exists some matching function for comparing features of the same type. The action selection part of this model extends the object recognition model in time and determines the optimal actions by the minimum expected entropy of the object predictions across all potential actions. 
        
    \subsubsection{Object Recognition Model}
        The object recognition subgraph discriminatively predicts object and pose based on observed features. This model consists of $N$ objects, $O \in \{o_1,o_2, ..., o_N\}$ in $I$ poses $P \in \{p_1,p_2, ..., p_I\}$ and 
        %resulting in $K = N \cdot I$ object-pose pairs. 
        $M$ derived features $\set{F} = \left\{ f_1, ...,  f_M\right\}$ where $f_i$ represents a  continuous random variable associated with the feature error.
        % of $J$ types $\set{F} = \{\set{F}^1,\set{F}^2, ..., \set{F}^J\}$. 
        The model assumes that derived features are conditionally independent given object and pose. The resulting graphical model is shown in \figref{fig:objectRecognitionSubgraph}.
        % f_m vs f^j confusion
        % \begin{equation}
        %     \label{eq:fac}
        %     \prob{O,P,\set{F}} = \prob{O}\prob{P}\prob{\set{F}|O,P}
        % \end{equation}
        \begin{figure}[h]
          \centering
          \begin{tikzpicture}
            % Define nodes
            \node[obs]                            (F) {$f$};
            \node[latent, above=of F, xshift=-1.5cm] (O) {$O$};
            \node[latent, above=of F, xshift=1.5cm]  (P) {$P$};

            % Connect the nodes
            \edge {P,O} {F};

            % Plates
            \plate {} {(F)} {$M$}
          \end{tikzpicture}
          \caption{Simple object recognition graph.}
          \label{fig:objectRecognitionSubgraph}
        \end{figure}

        The likelihood of a derived feature, $\prob{f|o,p}$ is a distribution derived from feature matching errors. Each feature in the model has an associated type $j$ and a value or descriptor with which to compute a matching error $\cursive{E}^j(\cdot,\cdot)$ with respect to another feature of the same type.
        
        In order to compute matching errors for each feature type, we construct a database $\set{D}$ of features that were extracted from images of each object and pose taken in an ideal setting. It is worth noticing that the number of all features $M$ is equal to the number of features that were initially extracted and are stored in the database $\set{D}$. % TODO: add that there is only one image per object-pose pair? What does ideal mean?

    %OLD
%        The features of this model are selected as the set of all unique features observed in an ideal setting for all objects and poses in the model. 

        Given an observation, $\set{F}_{\text{obs}}$, the best matching error with respect to a feature in the database $f^j \in \set{F}$ is given by \eqref{eq:bestMatch}.
        
        
        \begin{equation}
            \label{eq:bestMatch}
            \cursive{E}(f^j) = \min_{f^j_{\text{obs}} \in \set{F}_{\text{obs}}}\cursive{E}^j(f^j,f^j_{\text{obs}})
        \end{equation}
        
        Training data consists of $R$ sets of feature observations for each object-pose pair. The derived feature likelihood distribution is learned from the distribution of best matching errors across all training observations for a specific object-pose.
        
        
        \begin{equation}
            \prob{f|o,p} \sim \{\cursive{E}_1(f), ...,  \cursive{E}_R(f)\}
        \end{equation}
        Note that this procedure works for any type of feature given an error function, hence this model can also combine multiple feature types into a single object recognition model. The derived feature approximation significantly reduces the dimensionality of the random variable since a feature descriptor can be highly dimensional (e.g. for the SIFT descriptor it has 128 dimensions) whereas the function $\cursive{E}(f)$ returns a real number for each feature in the database $f^j \in \set{D}$.  
        
        Eventually, in order to obtain the probabilistic measure we learn a normal distribution for the derived feature likelihood. 

 
          
        \begin{equation}
            \prob{f|o,p} \sim \cursive{N}(\mu,\sigma)
        \end{equation}
        % OLD
            % \begin{equation}
            %     \prob{f_m|o_n,p_i} \sim \cursive{N}(\mu_{m}^{n,i},\sigma_{m}^{n,i})
            % \end{equation}
            % I would remove the m index here. It doesnt help much and it's not easily readable
        % \subsubsection{Object-Pose Inference}
        
        The posterior for predicting object-pose is given in \eqref{eq:firstPosterior}.
        \begin{equation}
            \label{eq:firstPosterior}
            \prob{o,p|\set{F}} = \frac{\prob{o,p} \cdot \prob{\set{F}|o,p}}{\prob{\set{F}}}
        \end{equation}
        Based on the assumption that features are conditionally independent given object and pose, the joint derived feature likelihood can be computed as a product shown in \eqref{eq:setFeatureLikelihood}.
        \begin{equation}
            \label{eq:setFeatureLikelihood}
            \prob{\set{F}|o,p} = \prod_{m=1}^{M} \prob{f_m|o,p}
        \end{equation}
        Assuming a uniform prior on objects and poses, the posterior can then be computed as shown in \eqref{eq:firstPosteriorComputation}.
        \begin{equation}
            \label{eq:firstPosteriorComputation}
            \prob{o,p|\set{F}} = \frac{\prod_{m=1}^{M} \prob{f_m|o,p}}{N \cdot I \cdot \sum_{n,i} \prob{\set{F}|o_n,p_i}}
        \end{equation}
    \subsubsection{Action Selection Model}
        For action selection, we extend the object-recognition subgraph into a time-series graph. Actions are modeled as $I$ pairwise relative pose transformations including the \italic{stay} action to determine when the algorithm has converged. The next pose, $P_{t+1}$ is dependent only on the previous pose, $P_t$ and the previous action $A_t$. This results in a graphical model shown in \figref{fig:fullGraph}.
        \begin{figure}[h]
          \centering
          \begin{tikzpicture}
            % Define nodes
            \node[obs] (F) {$\set{F}_1$};
            \node[latent, above=of F]  (P) {$P_1$};
            \node[latent, left=of P, xshift=-1.5cm] (O) {$O$};
            \node[obs, above=of P]  (A) {$A_1$};

            \node[latent, right=of F, xshift=1.5cm] (F2) {$\set{F}_2$};
            \node[latent, above=of F2]  (P2) {$P_2$};
            \node[latent, above=of P2]  (A2) {$A_2$};


            % Connect the nodes
            \edge {P,O} {F};
            \edge {P2,O} {F2};
            \edge {P,A} {P2};

            % Plates
            \plate {pf} {(F)} {$M$}
            \plate {pf2} {(F2)} {$M$}

            \plate {} {(F)(P)(A)(pf)} {$t=0$}
            \plate {} {(F2)(P2)(A2)(pf2)} {$t+1$}
          \end{tikzpicture}
          \caption{graph model}
          \label{fig:fullGraph}
        \end{figure}
        % \begin{figure}[h]
        %   \centering
        %   \begin{tikzpicture}
        %     % Define nodes
        %     \node[obs] (F) {$\set{F}_1$};
        %     \node[latent, above=of F]  (P) {$P_1$};
        %     \node[latent, left=of P, xshift=-1.5cm] (O) {$O$};
        %     \node[obs, above=of P]  (A) {$A_1$};

        %     \node[obs, right=of F, xshift=1.5cm] (F2) {$\set{F}_2$};
        %     \node[latent, above=of F2]  (P2) {$P_2$};
        %     \node[obs, above=of P2]  (A2) {$A_2$};

        %     \node[latent, right=of F2, xshift=1.5cm] (F3) {$\set{F}_3$};
        %     \node[latent, above=of F3]  (P3) {$P_3$};
        %     \node[latent, above=of P3]  (A3) {$A_3$};


        %     % Connect the nodes
        %     \edge {P,O} {F};
        %     \edge {P2,O} {F2};
        %     \edge {P3,O} {F3};
        %     \edge {P,A} {P2};
        %     \edge {P2,A2} {P3};

        %     % Plates

        %     \plate {pf} {(F)} {$M$}
        %     \plate {pf2} {(F2)} {$M$}
        %     \plate {pf3} {(F3)} {$M$}

        %     \plate {} {(F)(P)(A)(pf)} {$t=1$}
        %     \plate {} {(F2)(A2)(pf2)} {$t=2$}
        %     \plate {} {(F3)(A3)(pf3)} {$t=3$}

        %     \draw [dotted, thick] (7.5,1.5) -- (7.85,1.5);
        %   \end{tikzpicture}
        %   \caption{Generalized Model}
        %   \label{fig:fullGraph}
        % \end{figure}

        % \subsubsection{First Action}
        % After initially observing data $\set{F}_1$, we compute the posterior for all object-poses. We consider what is the optimal action $a \in A_1$ which would lead to a new pose $P_2$ and reveal new features $\set{F}_2$. This joint distribution is factorized by equation \ref{eq:firstActionFactorized}, depicted in figure \ref{fig:firstActionGraph}.

        % \begin{multline}
        %     \label{eq:firstActionFactorized}
        %     \prob{O,P_1,P_2,\set{F}_1, \set{F}_2, A_1} = \\ \prob{O}\prob{P_1}\prob{\set{F}_1|O,P}\prob{P_2|P_1|A_1}\prob{\set{F}_2|O,P_2}
        % \end{multline}

        %we can show how posterior looks for one action but after that let's stay with the generic formulation. Also with the graph - it should definitely be for n. That way it is more professional

        % The posterior for the after the first action is computed as a simple update of the first posterior shown in equation \ref{eq:firstActionPosterior}.

        % \begin{multline}
        %   \label{eq:firstActionPosterior}
        %   \prob{o|\set{F}_1,\set{F}_2,a} = \\ \frac{\sum_{P_1,P_2} \prob{o,P_1|\set{F}_1} \; \prob{\set{F}_2|P_2,o} \; \prob{P_2|P_1,a}}{\sum_{P_1,P_2,O} \prob{O,P_1|\set{F}_1} \; \prob{\set{F}_2|P_2,O} \; \prob{P_2|P_1,a}}
        % \end{multline}

        % To determine the optimal action we compute the minimum expected entropy of object prediction for the distribution in equation \ref{eq:firstActionPosterior} given by equation \ref{eq:firstActionOptimal}.
        %TODO: we need more explanation on this. Why expected entropy? why does it work?

        % \begin{equation}
        %   \label{eq:firstActionOptimal}
        %   a^* = \argmin_{A_1} \expectedValue{\entropy{O|\set{F}_1,\set{F}_2,A_1}}{\set{F}_2 \sim \prob{\set{F_2}|\set{F}_1,A_1}}
        % \end{equation}

        % \subsubsection{Generalized Optimal Action}
        
        The posterior at time $t+1$ given the entire history of observations and actions is simply a Bayesian update of the posterior at time $t$ given in \eqref{eq:fullPosterior}.
        \begin{multline}
            \label{eq:fullPosterior}
            \prob{o,P_{t+1}|\set{F}_{1:t+1},A_{1:t}} = \\ \frac{ \sum_{P_t} \prob{o,P_t|\set{F}_{1:t},A_{1:t-1}} \prob{\set{F}_{t+1}|o,P_{t+1}} \prob{P_{t+1}|P_t,A_t}}{\sum_{P_t,P_{t+1},O} \prob{O,P_t|\set{F}_{1:t},A_{1:t-1}} \prob{\set{F}_{t+1}|O,P_{t+1}} \prob{P_{t+1}|P_t,A_t}}
        \end{multline}
        For our experiment, we consider actions to be perfect, i.e. $\prob{P_{t+1}|P_t,A_t} \in \{ 0 , 1 \}$. Thus, given an action and a pose, the next pose can be computed deterministically. This simplifies our Bayesian update to \eqref{eq:fullPosteriorSimplified}.
        \begin{multline}
            \label{eq:fullPosteriorSimplified}
            \prob{o,P_{t+1}|\set{F}_{1:t+1},A_{1:t}} = \\ \frac{\prob{o,P_t|\set{F}_{1:t},A_{1:t-1}} \prob{\set{F}_{t+1}|o,P_{t+1}} }{\sum_{P_t,O} \prob{O,P_t|\set{F}_{1:t},A_{1:t-1}} \prob{\set{F}_{t+1}|O,P_{t+1}} }
        \end{multline}
        
        We defined the optimal action as moving an object into the least ambiguous pose resulting in a minimum entropy across predicted object probabilities. The posterior object probability $\prob{o|\set{F}_{1:t+1},A_{1:t}}$ is a distribution because we have not observed $\set{F}_{t+1}$. Thus, we minimize the \italic{expected} entropy of this posterior for all potential actions given by \eqref{eq:optimalAction}.
        \begin{equation}
            \label{eq:optimalAction}
            a^* = \argmin_{A_t} \expectedValue{ \entropy{O|\set{F}_{1:t+1},A_{1:t}} }{\set{F}_{t+1} \sim \prob{\set{F_{t+1}}|\set{F}_{1:t},A_{1:t}}}
        \end{equation}
        That can be efficiently computed with a particle filter approximate sampling method.

        % OLD
            % \subsubsection{Implementation}

            % This algorithm follows a simple posterior update rule
            % \begin{align}
            %     \text{posterior}_t &= \frac{\text{posterior}_{t-1}*\text{likelihood}_t}{\text{evidence}_t}\\
            %     &= \frac{\text{posterior}_{t-1}*\text{likelihood}_t}{\sum \text{posterior}_{t-1}*\text{likelihood}_t}
            % \end{align}

            % \begin{table}[h]
            %   \begin{tabular}{c|c|c|c} % number of columns and vertical lines
            %     \hline % top horizontal line
            %     Time & Posterior & Evidence & Likelihood\\
            %     [0.5ex] % [0.5ex] adds vertical space
            %     \hline\hline % inserts double-line
            %     0 & $\prob{o,p}$ & & \\[0.5ex] 
            %     1 & $\prob{o,p|\set{F}_1}$ & $\prob{\set{F}_1}$ & $\prob{\set{F}_1|o,p}$ \\[0.5ex] 
            %     2 & $\prob{o,p|\set{F}_1,\set{F}_2,A_1}$ & $\prob{\set{F}_2|\set{F}_1,A_1}$ & $\prob{\set{F}_2|o,p}$ \\
            %     ...&...&...&...\\[0.5ex] 
            %     t & $\prob{o,p|\set{F}_{1:t},A_{1:t-1}}$ & $\prob{\set{F}_t|\set{F}_{1:t-1},A_{1:t-1}}$ & $\prob{\set{F}_t|o,p}$
            %   \end{tabular}
            %   % \label{tab:updateRule}
            %   % \caption{Update cache}
            % \end{table}

            % Our implementation uses a particle filter for computing the optimal action.
            % this is not a particle filter stricte but we use MCMC method to approximate distributions. Also, we shouldn't put implementation in.

        % include derivations in the appendix
\subsection{Implementation}

\subsubsection{Object Recognition}
% TODO: Karol: write about SIFT features n stuff


\subsubsection{Action Selection}
% TODO: Chet: write about the implementation of our expected entropy calculation. What do we sample, you can also put the table you had before. Write whatever you think is relevant here. The more the better, we can trim it down later.
