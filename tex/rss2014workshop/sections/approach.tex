% !TEX root = ../main.tex
    \vspace{-3ex}
\section{Approach}
    \vspace{-0.5ex}

    % general probabilistic model 
        % object recognition
        % action selection

    % implementation
        % object recognition, features n stuff
        % action selection, sampling n stuff
The main idea behind our approach is to choose actions that minimize the uncertainty about the object in the scene. In order to achieve this goal, we first introduce our generic feature-based measurement model that is later used for probabilistic object recognition. In the next step, the model is extended into a time-series graph to incorporate actions. Finally, an expected entropy measure is used to find the optimal action that will minimize the uncertainty of the object.
\vspace{-1ex}
    \subsection{Probabilistic Graphical Model}
    \vspace{-0.5ex}
%        This model consists of an object recognition subgraph extended in time for modelling actions. This model is agnostic of the type of features used so long a matching error function is defined for computing the similarity features of the same type. Actions are optimally selected based the minimum expected entropy of the object predictions for each potential action.
		%In this section we present an overview of the probabilistic graphical model used in our approach. The model consists of measurement model, which is used for object recognition and it is extended into interactive object recognition model that includes actions.  
            
        \subsubsection{Measurement Model}
%            The object recognition subgraph discriminatively predicts object and pose based on observed features.            
            We use a causal measurement model $\prob{\set{F}|o,p}$ where object and pose cause the appearance of specific features that are observed by the robot. This model consists of $N$ discrete objects, $O \in \{o_1,o_2, ..., o_N\}$ in $I$ discrete poses $P \in \{p_1,p_2, ..., p_I\}$. In addition, we model $M$ features $\set{F} = \left\{ f_1, ...,  f_M\right\}$, where $\set{F}$ is an $M$-dimensional measurement vector of continuous random variables $f$. With these modelling choices we imply that features are conditionally independent given object and pose (see~\eqref{eq:setFeatureLikelihood}). The graphical model is shown in \figref{fig:objectRecognitionSubgraph}.

\vspace{-1ex}
            \begin{figure}[h]
              \centering
              \begin{tikzpicture}
                % Define nodes
                \node[obs]                            (F) {$f$};
                \node[latent, above=of F, xshift=-1.5cm] (O) {$O$};
                \node[latent, above=of F, xshift=1.5cm]  (P) {$P$};

                % Connect the nodes
                \edge {P,O} {F};

                % Plates
                \plate {} {(F)} {$M$}
              \end{tikzpicture}
              \caption{Subgraph representing a probabilistic measurement model.}
              \vspace{-2ex}
              \label{fig:objectRecognitionSubgraph}
            \end{figure}


              \vspace{-2ex}
\begin{align}
\label{eq:setFeatureLikelihood}
                \prob{\set{F}|o,p} &= \prod_{m=1}^{M} \prob{f_m|o,p}
\vspace{-2ex}
\end{align}


 
\subsubsection{Object Recognition}            
            The posterior of the object-pose is given by \eqref{eq:firstPosterior} assuming some prior, $\prob{o,p}$ and including the measurement model $\prob{\set{F}|o,p}$.
            \begin{align}
                \label{eq:firstPosterior}
                \prob{o,p|\set{F}} &= \frac{\prob{o,p} \cdot \prob{\set{F}|o,p}}{\prob{\set{F}}}\\                
                \label{eq:setFeatureEvidence}
                \prob{\set{F}} &= \sum_{n,i} \prob{\set{F}|o_n,p_i}\cdot \prob{o_n,p_i}
                \vspace{-2ex}
            \end{align}
%Please note that ~\eqref{eq:setFeatureLikelihood} is derived from conditional independence caused by the measurement model assumption.

        \subsubsection{Interactive Object Recognition}
            To model actions, the object-recognition subgraph is extended into a time-series graph. For each pose, actions are modeled as $I$ relative pose transformations including the \italic{stay} action. In this model the Markov assumption is used where the next pose, $P_{t+1}$ is dependent only on the previous pose, $P_t$ and the previous action $A_t$. This results in the graphical model shown in \figref{fig:fullGraph}.
            
           
                % After initially observing data $\set{F}_1$, we compute the posterior for all object-poses. We consider what is the optimal action $a \in A_1$ which would lead to a new pose $P_2$ and reveal new features $\set{F}_2$. This joint distribution is factorized by equation \ref{eq:firstActionFactorized}, depicted in figure \ref{fig:firstActionGraph}.

                % \begin{multline}
                %     \label{eq:firstActionFactorized}
                %     \prob{O,P_1,P_2,\set{F}_1, \set{F}_2, A_1} = \\ \prob{O}\prob{P_1}\prob{\set{F}_1|O,P}\prob{P_2|P_1|A_1}\prob{\set{F}_2|O,P_2}
                % \end{multline}

               

               

                % To determine the optimal action we compute the minimum expected entropy of object prediction for the distribution in equation \ref{eq:firstActionPosterior} given by equation \ref{eq:firstActionOptimal}.
              
                % \begin{equation}
                %   \label{eq:firstActionOptimal}
                %   a^* = \argmin_{A_1} \expectedValue{\entropy{O|\set{F}_1,\set{F}_2,A_1}}{\set{F}_2 \sim \prob{\set{F_2}|\set{F}_1,A_1}}
                % \end{equation}

            \begin{figure}[h]
                \centering
                \begin{tikzpicture}[scale=0.6, every node/.style={scale=0.6}]
                    % Define nodes
                    \node[obs] (F) {$f_1$};
                    \node[latent, above=of F]  (P) {$P_1$};
                    \node[latent, left=of P, xshift=-1.5cm] (O) {$O$};
                    \node[obs, above=of P]  (A) {$A_1$};

                    \node[obs, right=of F, xshift=1.5cm] (F2) {$f_2$};
                    \node[latent, above=of F2]  (P2) {$P_2$};
                    \node[obs, above=of P2]  (A2) {$A_2$};

                    \node[latent, right=of F2, xshift=1.5cm] (F3) {$f_3$};
                    \node[latent, above=of F3]  (P3) {$P_3$};
                    \node[latent, above=of P3]  (A3) {$A_3$};


                    % Connect the nodes
                    \edge {P,O} {F};
                    \edge {P2,O} {F2};
                    \edge {P3,O} {F3};
                    \edge {P,A} {P2};
                    \edge {P2,A2} {P3};

                    % Plates

                    \plate {pf} {(F)} {$M$}
                    \plate {pf2} {(F2)} {$M$}
                    \plate {pf3} {(F3)} {$M$}

                    \plate {} {(F)(P)(A)(pf)} {$t=1$}
                    \plate {} {(F2)(A2)(pf2)} {$t=2$}
                    \plate {} {(F3)(A3)(pf3)} {$t=3$}
                    
                    \plate [opacity=0.0] {hiddenPlate} {(F)(P)(pf)} {}
					\plate [dotted] {} {(F)(P)(O)(pf)(hiddenPlate)} {$\text{measurement model}$}

                    % \draw [dotted, thick, scale=0.6] (7.5,1.5) -- (7.85,1.5);
                \end{tikzpicture}
                \caption{Full probabilistic graphical model for interactive object recognition.}
                                \vspace{-1ex}
                \label{fig:fullGraph}
            \end{figure}
            
            The posterior at time $t+1$ given the entire history of observations and actions is a recursive Bayesian update of the posterior at time $t$ given in \eqref{eq:fullPosterior}.
            {\small
            \begin{multline}
                \label{eq:fullPosterior}
                \prob{o,P_{t+1}|\set{F}_{1:t+1},A_{1:t}} = \\ \frac{ \sum_{P_t} \prob{o,P_t|\set{F}_{1:t},A_{1:t-1}} \prob{\set{F}_{t+1}|o,P_{t+1}} \prob{P_{t+1}|P_t,A_t}}{\sum_{P_t,P_{t+1},O} \prob{O,P_t|\set{F}_{1:t},A_{1:t-1}} \prob{\set{F}_{t+1}|O,P_{t+1}} \prob{P_{t+1}|P_t,A_t}}
            \end{multline}
            }
\vspace{-2ex}
\subsubsection{Optimal Action Selection}            
            
            We introduce the optimal action for object recognition which is understood as moving the object into the pose in which the next measurement allows to maximally reduce the uncertainty of the object-pose. This results in a minimum entropy of the distribution of posterior object prediction probabilities. 

            Because we have yet to observe $\set{F}_{t+1}$, we must compute the \italic{expected} entropy of the posterior in \eqref{eq:fullPosterior}. The optimal action is selected as the action which minimizes the expected entropy of object prediction posteriors across all potential actions defined by \eqref{eq:optimalAction}.
            
            
            {
            \begin{equation}
            \label{eq:optimalAction}
            \small                
                A_t^* = \argmin_{A_t} \expectedValue{ \entropy{O|\set{F}_{1:t+1},A_{1:t}} }{\set{F}_{t+1} \sim \prob{\set{F_{t+1}}|\set{F}_{1:t},A_{1:t}}}
            \end{equation}
            }
            
            \vspace{-4ex}
    \subsection{Implementation}
%Hereby we describe our modelling choices for the measurement model as well as introduce the implementation of the optimal action selection algorithm.
        \subsubsection{Measurement Model}

%           \begin{itemize}
%           \item discuss how we create the database
%           \item what does it mean to have ideal images
%           \item what implementation of sift do we use
%           \item what matching algorithm do we use
%           \end{itemize}
 
            Each feature in the model has an associated type $j$ and a value or descriptor with which to compute a similarity or matching error $\cursive{E}^j(\cdot,\cdot)$ with respect to another feature of the same type. Object and pose can be predicted using the model $\prob{f|o,p}$, derived from matching errors between observed feature values, $\set{F}_{obs}$ and the set of reference feature values of the model, $\set{F}$. The features of the model are selected as the set of all unique features from all objects and poses observed in an ideal setting. Given an observation, $\set{F}_{\text{obs}}$, the best matching error $e$ with respect to a feature in the model $f^j \in \set{F}$ is given by \eqref{eq:bestMatch}.
            \begin{equation}
                \label{eq:bestMatch}
                e(f^j) = \min_{f^j_{\text{obs}} \in \set{F}_{\text{obs}}}\cursive{E}^j(f^j,f^j_{\text{obs}})
            \end{equation}
            
%            Training data consists of $R$ sets of observed features for each object-pose pair. The feature likelihood distribution is learned from the set of best matching errors for all training observations of a specific object-pose.
%            \begin{equation}
%                \prob{f|o,p} \sim \{\cursive{E}_1(f), ...,  \cursive{E}_R(f)\}
%            \end{equation}
%            Note that this procedure works for any type of feature given an error function. This model can also combine multiple feature types into a single measurement model. 

            For our model, we used SIFT~\cite{lowe2004distinctive} features and approximate a normal distribution for the feature likelihood.   
%            \begin{equation}
%                \prob{f|o,p} \sim \cursive{N}(\mu,\sigma)
%            \end{equation}

            The posterior probability~\eqref{eq:fullPosterior} is efficiently computed using dynamic programming.
            
%            \begin{equation}
%                \label{eq:firstPosteriorComputation}
%                \prob{o,p|\set{F}} = \frac{\prob{\set{F}|o,p}}{\sum_{n,i} \prob{\set{F}|o_n,p_i}}
%            \end{equation}

             
%            This simplifies our Bayesian update from \eqref{eq:fullPosterior} to \eqref{eq:fullPosteriorSimplified}.
%            {\small
%            \begin{multline}
%                \label{eq:fullPosteriorSimplified}
%                \prob{o,P_{t+1}|\set{F}_{1:t+1},A_{1:t}} = \\ \frac{\prob{o,P_t|\set{F}_{1:t},A_{1:t-1}} \prob{\set{F}_{t+1}|o,P_{t+1}} }{\sum_{P_t,O} \prob{O,P_t|\set{F}_{1:t},A_{1:t-1}} \prob{\set{F}_{t+1}|O,P_{t+1}} }
%            \end{multline}
%            }

            
%            \begin{align}
%                \text{posterior}_t &= \frac{\text{posterior}_{t-1}*\text{likelihood}_t}{\text{evidence}_t}\\
%                &= \frac{\text{posterior}_{t-1}*\text{likelihood}_t}{\sum \text{posterior}_{t-1}*\text{likelihood}_t}
%            \end{align}

%            This algorithm follows an efficient posterior update procedure, which is efficiently computed using dynamic programming by caching the values given in Table \ref{tab:dynamicProgramming}.
%            \begin{table}[h]
%                \centering
%                \begin{tabular}{c|c|c|c} % number of columns and vertical lines
%                    \hline % top horizontal line
%                    Time & Posterior & Evidence & Likelihood\\
%                    [0.5ex] % [0.5ex] adds vertical space
%                    \hline\hline % inserts double-line
%                    0 & $\prob{o,p}$ & & \\[0.5ex] 
%                    1 & $\prob{o,p|\set{F}_1}$ & $\prob{\set{F}_1}$ & $\prob{\set{F}_1|o,p}$ \\[0.5ex] 
%                    2 & $\prob{o,p|\set{F}_1,\set{F}_2,A_1}$ & $\prob{\set{F}_2|\set{F}_1,A_1}$ & $\prob{\set{F}_2|o,p}$ \\
%                    ...&...&...&...\\[0.5ex] 
%                    t & $\prob{o,p|\set{F}_{1:t},A_{1:t-1}}$ & $\prob{\set{F}_t|\set{F}_{1:t-1},A_{1:t-1}}$ & $\prob{\set{F}_t|o,p}$
%                \end{tabular}
%                \caption{Cache for dynamic programming.}
%                \label{tab:dynamicProgramming}
%            \end{table}

            \subsubsection{Optimal Action Selection}

                To efficiently compute the expected entropy given in \eqref{eq:optimalAction}, the posterior distribution is sampled for each action using a Monte Carlo method. 

                First, the evidence distribution given in \eqref{eq:evidenceDistribution} is sampled.

                {\small
                \begin{multline}
                    \label{eq:evidenceDistribution}
                    \prob{\set{F}_{t+1}|\set{F}_{1:t}, A_{1:t}} = \\ \sum_{P_t,P_{t+1},O}  \prob{\set{F}_{t+1}|O,P_{t+1}} \prob{P_{t+1}|P_t,A_t} \prob{O,P_t|\set{F}_{1:t},A_{1:t-1}}
                \end{multline}
                }

%                Because actions are deterministic, this simplfies to \eqref{eq:evidenceDistributionSimplified}.
%
%                {\small
%                \begin{equation}
%                    \label{eq:evidenceDistributionSimplified}
%                    \prob{\set{F}_{t+1}|\set{F}_{1:t}, A_{1:t}} = \sum_{P_t,O} \prob{O,P_t|\set{F}_{1:t},A_{1:t-1}} \prob{\set{F}_{t+1}|O,P_{t+1}}
%                \end{equation}
%                }

                This distribution can be sampled trivially by first sampling object-poses based on the distribution defined by the previous posterior, $\prob{O,P_t|\set{F}_{1:t},A_{1:t-1}}$. Then, for each sampled object-pose, a particle representing a potential next observation is sampled from the feature likelihood distribution $\prob{\set{F}_{t+1}|O,P_{t+1}}$. In our experiment, we consider a perfect actuator that can deterministically execute actions, i.e. $\prob{P_{t+1}|P_t,A_t} \in \{ 0 , 1 \}$. Thus, given an action and a pose, the next pose can be computed deterministically.

                The next posterior is then computed by \eqref{eq:fullPosterior} for each particle. The posterior object probability is computed by marginalization given in \eqref{eq:objectPosterior}.

                \begin{equation}
                    \label{eq:objectPosterior}
                    \prob{O|\set{F}_{1:t+1},A_{1:t}} = \sum_{P_{t+1}} \prob{O,P_{t+1}|\set{F}_{1:t+1},A_{1:t}}
                \end{equation}

                The entropy of the posterior object probabilities is computed for each particle and then averaged to give the expected entropy of the object posterior. 

                This is computed for each potential action and the optimal action is selected according to \eqref{eq:optimalAction} by the action which leads to the minimal expected entropy across object probabilities.
